ğŸ“˜ Project Overview

This project builds an AI-powered Fact Checking System that verifies user claims using:

* Government-sourced factual data (PIB RSS feeds)
* Sentence-transformer embeddings for similarity search
* FAISS vector database for retrieval
* spaCy for claim extraction
* Groq LLaMA-3.1/3.3 70B for final fact verification
* Gradio UI for interactive usage

The system collects factual statements from authentic government RSS sources, embeds them, retrieves the most relevant evidence when a user submits a claim, and finally uses an LLM to determine whether the claim is True, False, or Unverifiable.

ğŸ“‘ Table of Contents

1. Project Overview
2. Features
3. Technology Stack
4. Why These Technologies
5. System Architecture
6. Environment Setup
7. API Keys & Authentication
8. Hugging Face Token
9. Groq API Key
10. Installation Steps
11. Running the Full Pipeline
12. Using the Gradio App
13. Troubleshooting
14. Future Improvements


ğŸš€ Features

* Fetches real-time factual data from PIB (Press Information Bureau) RSS feeds
* Cleans and compiles data into a structured CSV database
* Uses all-MiniLM-L6-v2 to generate dense vector embeddings of facts
* Fast vector similarity search using FAISS
* Automatic claim extraction via spaCyâ€™s NLP pipeline
* Uses Groq's LLaMA-3.1/3.3 70B to evaluate claim truthfulness
* Provides structured JSON outputs with:
    1. verdict
    2. confidence
    3. reasoning
    4. evidence used
* Clean and interactive Gradio UI for public use
* Fully modular for future dataset additions and model upgrades

ğŸ§  Technology Stack
Core Components
Component	                    Technology Used	Purpose
Claim extraction	            spaCy (en_core_web_md)	Extract sentences, entities, and keywords
Embeddings	                    sentence-transformers / MiniLM	Create dense vector representations
Vector store	                FAISS	Fast similarity search
Verification LLM	            Groq (LLaMA 3.1 / 3.3 70B)	Final verdict generation
UI	                            Gradio	Interactive front-end
Data source	                    PIB RSS Feeds	Verified government releases

ğŸ’¡ Why These Technologies
ğŸ”¹ SentenceTransformers (MiniLM-L6-v2)
* Lightweight, fast, 384-dimensional embeddings
* High accuracy for semantic similarity tasks
* Works well with large datasets

ğŸ”¹ FAISS

* Industry-standard vector store used by Meta, NVIDIA, OpenAI
* Blazing fast ANN (approximate nearest neighbor) search
* Runs fully in-memory without external services

ğŸ”¹ spaCy

* Efficient NLP pipeline for sentence segmentation, POS tagging, and entity extraction
* Medium model (en_core_web_md) gives a good balance of accuracy & speed

ğŸ”¹ Groq LLaMA Models

* Groq LPU hardware gives insanely fast inference (10â€“500 tokens/ms)
* Free API tier available
* More deterministic than OpenAI for structured JSON outputs

ğŸ”¹ Gradio

* Easiest way to build production-ready ML apps
* Supports sliders, textboxes, examples, themes

ğŸ— System Architecture
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ 1. Fetch PIB RSS Feeds       â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ 2. Parse & Clean Feed Data   â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ 3. Store in CSV Database     â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ 4. Chunk Text & Create       â”‚
     â”‚    Embeddings (MiniLM)       â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ 5. Build FAISS Index         â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ 6. User Inputs Claim         â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ 7. Extract Claim (spaCy)     â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ 8. Retrieve Top-k Evidence   â”‚
     â”‚    (FAISS)                   â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ 9. Verify with Groq LLM      â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ 10. Display Verdict (UI)     â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ›  Environment Setup
Recommended environments:

* Google Colab (preferred â€” GPU not required)
Local system with:
    * Python 3.9 â€“ 3.11
    * 8 GB RAM minimum

ğŸ” API Keys & Authentication

1ï¸âƒ£ Generate Hugging Face Token
This token allows you to download embedding models.
Steps:

1. Visit: https://huggingface.co/settings/tokens
2. Click New Token
3. Set permissions â†’ Read
4. Copy the token
5. Add to environment:
6. export HF_TOKEN="your_hf_token_here"

2ï¸âƒ£ Generate Groq API Key
Required for LLaMA-3 inference.
Steps:

1. Go to https://console.groq.com/keys
2. Click Create API Key
3. Copy the key
4. Add to environment:
5. export GROQ_API_KEY="your_groq_api_key_here"

ğŸ“¦ Installation Steps

Inside your notebook, run:

!pip install -q sentence-transformers faiss-cpu spacy gradio pandas groq huggingface_hub feedparser beautifulsoup4 requests lxml
!python -m spacy download en_core_web_md

â–¶ï¸ Running the Full Pipeline

Once dependencies are installed:

Run Cell 1â€“7 to fetch and build the factual dataset.

Run Cell 8 to embed and index facts.

Run Cell 9â€“12 for claim extraction, retrieval, and LLM verification.

Run Cell 13 to test the fact checker.

Run Cell 14 to launch the Gradio UI.

ğŸŒ Launching the App

After running Cell 14:
A Gradio link appears
Open it in a browser
Enter any claim

The system will:
Extract claim
Retrieve top evidence
Evaluate via LLaMA on Groq
Provide verdict + reasoning

Example output:

âœ… VERDICT: True
Confidence: 91%
Reasoning: The retrieved evidence confirms...
1. Evidence text...
2. Evidence text...

â— Troubleshooting
Issue	                        Solution
FAISS index shape mismatch	    Ensure embeddings are all float32
Groq API Error	                Check your API key + billing limits
Cannot download HF model	    Ensure HF token has read permission
RSS feeds return 403	        Add custom user-agent (already included)
Very few facts extracted	    PIB sometimes rate-limits â€” wait 10 minutes

ğŸš€ Future Improvements

Add multilingual fact checking
Integrate NewsAPI, LokSabha Debates, RTI databases
Add web search retrieval (Bing / Tavily)
Reinforcement Learning for Chain-of-Thought verification
Weighted evidence scoring instead of simple L2 distance
